{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAukc81k3V/nWPSR7IqsaS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luckynirwan12/Web-Crawling/blob/main/Web_Crawling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web **Crawling**"
      ],
      "metadata": {
        "id": "yiGvguLaNMtd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqVtJYjLxdVk",
        "outputId": "43217cf7-bfc3-4560-b259-b9f84ef854f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests-html in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.32.3)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.0.1)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.2.0)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.11/dist-packages (from requests-html) (1.20.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.11/dist-packages (from requests-html) (0.0.2)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.3.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.0.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (2025.6.15)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.7.0)\n",
            "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (11.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.67.1)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.26.20)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (10.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4->requests-html) (4.13.4)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyquery->requests-html) (5.4.0)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyquery->requests-html) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->requests-html) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->requests-html) (3.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.14.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4->requests-html) (2.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.11/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (4.14.0)\n",
            "Collecting lxml_html_clean\n",
            "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from lxml_html_clean) (5.4.0)\n",
            "Downloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: lxml_html_clean\n",
            "Successfully installed lxml_html_clean-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install requests-html\n",
        "!pip install requests\n",
        "!pip install bs4\n",
        "!pip install lxml_html_clean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import deque\n",
        "from urllib.parse import urlsplit\n",
        "from requests_html import HTMLSession\n",
        "import threading\n",
        "import time\n",
        "import urllib3\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "QiPp-8UExuze"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#user_url = \"https://www.thapar.edu/sitemap.xml\"\n",
        "#url = [\"https://www.thapar.edu\"]\n",
        "EMAIL_REGEX = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\""
      ],
      "metadata": {
        "id": "-0En0MHOywWh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable SSL warnings (not recommended in production)\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "# Function to extract all URLs from sitemap XML\n",
        "def get_urls_of_xml(xml_url):\n",
        "    r = requests.get(xml_url, verify=False)       # Fetch sitemap, ignore SSL verification\n",
        "    xml = r.text                                  # Get raw XML content\n",
        "    soup = BeautifulSoup(xml, 'xml')              # Parse XML properly using 'xml' parser\n",
        "    links_arr = []                                # List to store URLs\n",
        "\n",
        "    for link in soup.findAll('loc'):              # Look for all <loc> tags\n",
        "        linkstr = link.get_text(strip=True)       # Extract text inside <loc>\n",
        "        links_arr.append(linkstr)                 # Add to the list\n",
        "\n",
        "    return links_arr                              # Return all collected URLs"
      ],
      "metadata": {
        "id": "qB2-8Gnwy75T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function with the sitemap URL\n",
        "links_data_arr = get_urls_of_xml(\"https://thapar.edu/sitemap.xml\")\n",
        "\n",
        "# (Optional) Print few links to confirm it's working\n",
        "print(links_data_arr[:5])  # Show first 5 URLs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coZb2yJ41Imr",
        "outputId": "ba63cd74-be87-4862-c64c-2b1b4decda45"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['http://thapar.edu/', 'http://thapar.edu/programmes', 'http://thapar.edu/admissions', 'http://thapar.edu/aboutus', 'http://thapar.edu/students']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-19-726831832.py:11: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n",
            "  for link in soup.findAll('loc'):              # Look for all <loc> tags\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session = HTMLSession()  # Create a session for advanced browsing\n",
        "email = set()            # Store unique emails (set avoids duplicates)\n",
        "\n",
        "for i in tqdm(links_data_arr):\n",
        "    try:\n",
        "        # Use session.get with verify=False to bypass SSL check\n",
        "        r = session.get(i, verify=False)\n",
        "\n",
        "        # Extract emails from the page\n",
        "        for re_match in re.finditer(EMAIL_REGEX, r.html.raw_html.decode()):\n",
        "            email.add(((re_match.group())).replace(\"-\", \"\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error while processing {i}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUgo6pjm1T88",
        "outputId": "83fbb687-8da4-4dc3-9de4-73ba72c4b73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 1014/4342 [14:36<36:44,  1.51it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Error while processing http://thapar.edu/AnnexureI.htm: 'utf-8' codec can't decode byte 0xa0 in position 721: invalid start byte\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 1615/4342 [25:44<36:18,  1.25it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Error while processing http://lmtsom.thapar.edu: HTTPConnectionPool(host='lmtsom.thapar.edu', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79a8f57dab90>: Failed to establish a new connection: [Errno -2] Name or service not known'))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 1651/4342 [26:18<1:06:06,  1.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Error while processing http://admissions.thapar.edu/?_ga=2.45427623.2046722684.1520064571-176534119.1510131791: HTTPConnectionPool(host='admissions.thapar.edu', port=80): Max retries exceeded with url: /?_ga=2.45427623.2046722684.1520064571-176534119.1510131791 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79a8f62ce0d0>: Failed to establish a new connection: [Errno 113] No route to host'))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 2210/4342 [35:00<42:01,  1.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Error while processing http://www.thapar.edu/images/NATIONAL%20CONFERENCE.htm: 'utf-8' codec can't decode byte 0x93 in position 2013: invalid start byte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▊  | 3419/4342 [55:34<20:21,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error while processing http://csed.thapar.edu/faculties/category/departments/basic-engineering-sciences1: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 3811/4342 [1:03:02<05:56,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error while processing http://www.thapar.edu/upload/files/ClientAuth_CA.scc: 'utf-8' codec can't decode byte 0x82 in position 1: invalid start byte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 3818/4342 [1:03:07<04:37,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error while processing http://www.thapar.edu/pages/event/during-and-after-covid-193: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 4254/4342 [1:10:24<02:04,  1.42s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the set of emails into a pandas DataFrame\n",
        "df = pd.DataFrame(email, columns=[\"Email\"])\n",
        "\n",
        "# Save the DataFrame as a CSV file named 'Emails.csv' without row index\n",
        "df.to_csv(\"Emails.csv\", index=False)\n",
        "\n",
        "# Print a success message when the CSV file is saved\n",
        "print(\"✅ Emails saved to Emails.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISf8RLAmMnuI",
        "outputId": "819119ee-bead-4fa8-fecc-447bf2115e24"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Emails saved to Emails.csv\n"
          ]
        }
      ]
    }
  ]
}