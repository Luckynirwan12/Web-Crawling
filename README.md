# Web Crawling
## ğŸ“§ Email Crawler & Extractor ğŸ”
This Python program crawls a website using its sitemap.xml and extracts all the email addresses found across the listed pages. The emails are saved into a clean CSV file.

## ğŸ“¥ Input
- A valid URL to a website's sitemap.xml.
Example:

      https://yourdomain.com/sitemap.xml

## ğŸ“¤ Output
- A CSV file named Emails.csv containing all the extracted email addresses:

      Email
      example1@domain.com
      example2@domain.com
      ...

## âš™ï¸ Features
- Crawls thousands of web pages listed in a sitemap.

- Extracts unique email addresses using regular expressions.

- Bypasses SSL certificate errors when needed.

- Saves results in a structured CSV file using pandas.

- Displays progress with a progress bar using tqdm.

## ğŸ› ï¸ Technologies Used
- requests, requests-html â€“ for HTTP requests

- BeautifulSoup â€“ to parse sitemap XML

- re â€“ to extract email patterns

- pandas â€“ to store and export results

- tqdm â€“ for progress tracking

## ğŸš€ How to Run
1. Install required packages:

       pip install requests requests-html pandas beautifulsoup4 tqdm
2. Run the script and update the sitemap URL as needed:

       links_data_arr = get_urls_of_xml("https://thapar.edu/sitemap.xml")
3. Output: A CSV file named Emails.csv will be created with all found email addresses.
